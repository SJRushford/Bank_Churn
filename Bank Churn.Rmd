---
title: "Predicting Bank Churn"
author: "Scott Rushford"
date: "`r Sys.Date()`"
output:
  pdf_document: default
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Predicting Bank Churn

[@base]

```{r R version, echo=FALSE}
version$version.string
```

## Executive Summary

The ABC Multinational Bank, operating in France, Germany and Spain, is looking to improve customer retention. They have provided customer data of account holders found on [Kaggle](https://www.kaggle.com/datasets/gauravtopre/bank-customer-churn-dataset) to use for this purpose. The object of this project is to develop a classification algorithm using R programming to predict bank churn.

```{r Libraries and Data, include=FALSE}
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(knitr)) install.packages("knitr", repos = "http://cran.us.r-project.org")
if(!require(corrplot)) install.packages("corrplot", repos = "http://cran.us.r-project.org")
if(!require(tinytex)) install.packages("tinytex", repos = "http://cran.us.r-project.org")

library(tidyverse)
library(caret)
library(knitr)
library(corrplot)
library(tinytex)

churn_url = "https://raw.githubusercontent.com/SJRushford/Bank_Churn/refs/heads/main/Bank%20Customer%20Churn%20Prediction.csv"

# Read Data
churn <- as_tibble(read_csv(url(churn_url)))
```

The data frame consists of 10,000 rows of bank customers containing 12 columns of customer information.

1.  customer ID - a number used to identify the customer

2.  Credit Score - a numeric value indicating the customer's current credit score

3.  Country - a factor of 3 levels: France, Germany, Spain indicating the customer's country of residence.

4.  Gender - a factor of 2 levels: Male, Female.

5.  Age - a numeric value indicating the customer's age.

6.  Tenure - the number of years the customer has been with the bank.

7.  Balance - numeric value indicating the current bank balance.

8.  Number of Products - a numeric value indicating the number of bank products the customer holds.

9.  Credit Card - a factor of 2 levels represented by 0 = no card, 1 = card.

10. Active Member - a factor of 2 levels represented by 0 = not active, 1 = active with a mean of 0.5151.

11. Estimated Salary - the customer's salary as estimated by the bank.

12. Churn - Churn is a factor of 2 levels represented by 0 = customer, 1 = churn with a mean of 0.2037 and is the target for prediction.

[@topre]

The key steps involved in this project included:

1.  Correlation and Principal Component Analysis

2.  Data Visualization

3.  Establish Baseline Measurements

4.  Test, Train and Validate machine learning algorithms.

5.  Review Results

## Methods & Analysis

### Correlation and Principle Component Analysis

A Correlation Analysis and a Principle Component Analysis was run on the data. These analyses do not show a significant correlation between any of the variables and churn, but does suggest some correlation between churn, gender, age and bank balance.

```{r Correlation Plot, echo=FALSE}

churn_CA <- churn %>% 
  mutate(country = replace(country, country == "France", 1),
         country = replace(country, country == "Germany", 2), 
         country = replace(country, country == "Spain", 3))
         
churn_CA <- churn_CA %>% 
  mutate(gender = replace(gender, gender == "Female", 1), 
         gender = replace(gender, gender == "Male", 0))

churn_CA <- churn_CA %>% 
  mutate_if(is.character, as.numeric)
CCA <- cor(churn_CA)

```

```{r corrplot, echo=FALSE}
corrplot(CCA, method = "color")
```

[@corrplot]

The lack of any strong correlation between any of the variables and churn are confirmed in the Principal Component Analysis where the proportion of variance ranges from 5.5% to 13.07%.

```{r Normalize, include=FALSE}
churn_norm <- as_tibble(scale(churn_CA))

# Remove customer ID as its purpose is to identify a customer only

churn_norm <- churn_norm %>% 
  select(-customer_id)

churn_pca <- prcomp(churn_norm)
```

```{r PCA Summary, echo=FALSE}
summary(churn_pca)
```

```{r PCA Biplot, include=FALSE}
biplot(churn_pca, scale = 0)
```

[@soetewey][@irizarry2019]

### Data Visualization

Box plots, histograms, bar graphs and line plots were created to visualize the data to gather additional insights.

```{r Rename columns, include=FALSE}
churn <- churn %>% 
  rename(id = customer_id, score = credit_score, products = products_number,
         card = credit_card, active = active_member, salary = estimated_salary)

```

```{r Box plots, include=FALSE}
if(!require(gridExtra)) install.packages("gridExtra", repos = "http://cran.us.r-project.org")

library(gridExtra)

bp1 <- boxplot(score ~ churn, data = churn)
bp1
mean(churn$score)

# mean credit score is 650.53
bp2 <- boxplot(age ~ churn, data = churn)
bp2
mean(churn$age)
# mean age is 38.92 years

bp3 <- boxplot(tenure ~ churn, data = churn)
bp3
mean(churn$tenure)
# mean tenure is 5.01 years

bp4 <- boxplot(balance ~ churn, data = churn)
bp4
mean(churn$balance)
# mean bank balance is 76,485.89

bp5 <- boxplot(products ~ churn, data = churn)
bp5
mean(churn$products)
# mean products is 1.53

bp6 <- boxplot(salary ~ churn, data = churn)
bp6
mean(churn$salary)
```

```{r Credit Score Box Plot, echo=FALSE}
boxplot(score ~ churn, data = churn)

```

The box plots for churn and credit score show similarities in median, and upper and lower quantiltes. The lower extreme for churn (1) extends below that of customers (0) with outliers which would indicate that a credit score of less than that 400 would increase the probability of churn.

```{r Boxplot Age, echo=FALSE}
boxplot(age ~ churn, data = churn)
```

The median, upper and lower quartiles and upper extreme are higher for churn (1) than customer (0). The box plot suggests that the probability of churn increases as customers become older than 40 and that customers over 60 are considered outliers.

```{r Boxplot Balance, echo=FALSE}
boxplot(balance ~ churn, data = churn)
```

The median, upper and lower quartiles and upper extreme are higher for churn (1) than customer (0). The box plot suggests that the probability of churn increases as customers begin to carry a bank balance that exceeds 100,000. increase the probability of churn.

[@base][@irizarry2019a]

### Histograms

```{r Histograms, include=FALSE}
h1 <- churn %>% 
  ggplot(aes(score)) +
  geom_histogram(bins = 10, col = "black", fill = "red")


h2 <- churn %>% 
  ggplot(aes(age)) +
  geom_histogram(bins = 10, col = "black", fill = "red")


h3 <- churn %>% 
  ggplot(aes(tenure)) +
  geom_histogram(bins = 5, col = "black", fill = "red")

h4 <- churn %>% 
  filter(balance > 0) %>% 
  ggplot(aes(balance)) +
  geom_histogram(bins = 10, col = "black", fill = "red")

h5 <- churn %>% 
  ggplot(aes(products)) +
  geom_histogram(bins = 4, col = "black", fill = "red")

h6 <- churn %>% 
  ggplot(aes(salary)) +
  geom_histogram(bins = 10, col = "black", fill = "red")

```

```{r Histograms Grid, echo=FALSE}

grid.arrange(h1, h2, h3, h4, h5, h6, nrow = 2, ncol = 3)
```

[@gridExtra][@ggplot2]

From examining the histograms a profile of the typical ABC Bank customer begins to emerge:

1.  a credit score greater than 500

2.  under the age of 50

3.  a tenure with the bank of 4 to 6 year duration

4.  maintains a bank balance of 100,000 to 150,000

5.  has 1 or 2 of the banks 4 products.

```{r Bar Graphs, include=FALSE}
b1 <- churn %>% 
  ggplot(aes(country)) +
  geom_bar(col = "black", fill = "red")


b2 <- churn %>% 
  ggplot(aes(gender)) +
  geom_bar(col = "black", fill = "red")

b3 <- churn %>% 
  ggplot(aes(active)) +
  geom_bar(col = "black", fill = "red")

b4 <- churn %>% 
  ggplot(aes(churn)) +
  geom_bar(col = "black", fill = "red")

```

```{r Bar Graphs Grid, echo=FALSE}
# Bar Graphs
grid.arrange(b1, b2, b3, b4, nrow = 2, ncol = 2)
```

[@ggplot2][@gridExtra]

The bar graphs provide additional insight into the customer base:

1.  Approximately half of their 10000 customers reside in France with the remaining 5000 split equally between Spain and Germany.

2.  Males make up 55% of the customer base and 45% are Female.

3.  The number of active members make up just over half the dataset.

4.  The churn rate is over 20%.

### Line Plots

Line plots were created to compare churn against all variables. Since this is a classification problem the GAM (General Additive Model) method was used for most of the plots except for the active, products and card variables where the LM (Linear Model) method was used.

```{r Line plots, include=FALSE}
# Plots
p1 <- churn %>% 
  ggplot(aes(score,churn)) +
  geom_smooth(method = "gam")

p2 <- churn %>% 
  ggplot(aes(age,churn)) +
  geom_smooth(method = "gam")

p3 <- churn %>% 
  ggplot(aes(tenure,churn)) +
  geom_smooth(method = "gam")

p4 <- churn %>% 
  ggplot(aes(balance,churn)) +
  geom_smooth(method = "gam")

p5 <- churn %>% 
  ggplot(aes(products,churn)) +
  geom_smooth(method = lm)

p6 <- churn %>% 
  ggplot(aes(card,churn)) +
  geom_smooth(method = lm)

p7 <- churn %>% 
  ggplot(aes(active,churn)) +
  geom_smooth(method = lm)

p8 <- churn %>% 
  ggplot(aes(salary,churn)) +
  geom_smooth(method = "gam")

```

```{r Line Plots Grid, echo=FALSE}
grid.arrange(p1, p2, p3, p4, p5, p6, p7, p8, nrow = 2, ncol = 4)
```

[@ggplot2][@gridExtra]

The line plots confirm the observations seen in other visuals: churn rate increases for customers with a credit score less than 500. The probability of churn increases for customers over 40 years of age, peaks at age 50 and then decreases at a similar rate. The probability churn increases as customers begin carrying account balances greater than 150,000.

### Baseline

In order to compare the models developed in this project, 2 baseline models were created. The first model consisted of a random draw of 0s and 1s producing a random list of 5000 zeros and 5000 ones. When the random list was compared to the actual data set it predicted the actual at an accuracy rate of 50.02%. This model is referred to as: random_n.

The second model was a random set of 0s and 1s in proportion to what appears in the data set. This produced a random list with 79.63% of the numbers being 0 and 20.37% of the numbers being 1. When this model was compared to the actual data set it was accurate to 67.33%. This model is referred to as: random_p.

```{r Random Samples, include=FALSE}
set.seed(3)
random_n <- rbinom(10000, 1, 0.5)
score_random_n <- bind_cols(as.numeric(random_n),as.numeric(churn$churn)) %>% 
  rename(predict = ...1, test = ...2) %>% 
  mutate(score = if_else(predict == test, 1, 0))
  
score_n <- sum(score_random_n$score)/10000

# Using an equal number of 0s and 1s predicted churn to a 50.02 %
# accuracy.

# Test based on the actual proportions of 0s (79.63%) and 1s (20.37%) in 
# the churn column

set.seed(3)
sum(churn$churn)
p <- mean(churn$churn)
random_p <- rbinom(10000, 1, p)
score_random_p <- bind_cols(as.numeric(random_p),as.numeric(churn$churn)) %>% 
  rename(predict = ...1, test = ...2) %>% 
  mutate(score = if_else(predict == test, 1, 0))

score_p <- sum(score_random_p$score)/10000

scores <- data.frame(model=c('random_n', 'random_p'),
                             score=c(0.5002, 0.6733),
                     PPV=c(0,0), NPV=c(0, 0))
```

[@base]

### Data Preparation

In order to use the machine learning algorithms that data was changed in the following ways:

1.  Columns were renamed for simplification.

2.  Country and Gender were changed from character strings to factors.

3.  The variables active, card and the predicted value churn were converted from numeric to factors.

4.  Customer ID and Estimated Salary were removed from the data set. The ID number is a unique or independent variable so it has no predictive value. As salary is an estimated value and there is no data indicating how that estimated was made or its accuracy therefore, the variable was removed.

5.  The data was normalized for classification.

```{r Data Prep, include=FALSE}
churn_cdp <- churn %>% 
  select(-id, -salary) %>% 
  mutate_at(c('country', 'gender', 'card', 'active', 'churn'), as.factor) %>% 
  mutate(across(where(is.numeric), scale))
```

## Optimize, Train, Test and Validate

The data set was partitioned by a ratio of 60:20:20 into sets from training, testing and validation respectively.

```{r Data Partition, include=FALSE}
# Create training, test and validation sets 60:20:20 @caret
set.seed(1, sample.kind="Rounding") # if using R 3.6 or later
# set.seed(1) # if using R 3.5 or earlier
train_index <- createDataPartition(y = churn_cdp$churn, times = 1, p = 0.6, list = FALSE)
train_churn <- churn_cdp[train_index,]
test_index <- createDataPartition(y = train_churn$churn, times = 1, p = 0.5, list = FALSE)
test_churn <- train_churn[test_index, ]
val_churn <- train_churn[-test_index, ]

# Set training control for optimizing parameters.
control <- trainControl(method = "cv", number = 10, p = .9)
```

[@caret]

The following process was followed for each model

1.  Optimization of the model parameters using cross validation and bootstrapping methods.

2.  Model Creation.

3.  Train Model

4.  Test Model

5.  Validate Model on the entire data set

6.  Evaluate each model based on its overall accuracy and its positive and negative predictive values. The positive value in this instance is 0, being a current customer and the negative value is 1, churn or not being a customer.

### k Nearest Neighbor

The k Nearest Neighbor model was created with k = 33. This means that each point is compared to the next closest 33 points, the neighborhood, and computes the average of 0s and 1s in each neighborhood.

```{r knn opt, include=FALSE}
set.seed(3)
churn_knn <- train(churn ~ ., method = "knn", 
               data = churn_cdp, tuneGrid = data.frame(k = seq(11, 71, 2)))
```

```{r}
ggplot(churn_knn, highlight = TRUE)
```

```{r knn, include=FALSE}
set.seed(3)
churn_knn3 <- knn3(churn ~ ., k = 33, data = train_churn)

# Test
pred_knn3 <- predict(churn_knn3, test_churn, type = "class")
cm_knn3 <- confusionMatrix(pred_knn3, test_churn$churn)
cm_knn3

# Validate 
set.seed(3)
val_knn3 <- predict(churn_knn3, val_churn, type = "class")
cm_knn3_val <- confusionMatrix(val_knn3, val_churn$churn)
cm_knn3_val

scores <- scores %>%
  add_row(model = 'knn', score = cm_knn3_val$overall["Accuracy"],
          PPV = cm_knn3_val$byClass['Pos Pred Value'], 
          NPV = cm_knn3_val$byClass['Neg Pred Value'])

```

```{r kNN Plot, echo=FALSE}
# Plot kNN https://www.geeksforgeeks.org/contour-of-knn-model-in-ggplot-using-r/
# Define the grid limits
x_min <- min(train_churn$age) - 1
x_max <- max(train_churn$age) + 1
y_min <- min(train_churn$balance) - 1
y_max <- max(train_churn$balance) + 1

# Create a grid of values
grid <- expand.grid(age = seq(x_min, x_max, by = 0.1),
                    balance = seq(y_min, y_max, by = 0.1))

# Base plot with original data points
base_plot <- ggplot(train_churn, aes(x = age, y = balance, 
                                     color = churn)) +
  geom_point(size = 2) +
  labs(title = "k-NN Decision Boundaries",
       x = "age",
       y = "balance") +
  theme_minimal()
base_plot

```

```{r knn test validate comp, echo=FALSE}
comp_knn3 <- data.frame(Model=c('Test', 'Validate'),
                        Accuracy=c(cm_knn3$overall["Accuracy"],
                                   cm_knn3_val$overall["Accuracy"]),
                        CI_Lower=c(cm_knn3$overall["AccuracyLower"],
                               cm_knn3_val$overall["AccuracyLower"]),
                        CI_Upper=c(cm_knn3$overall["AccuracyUpper"],
                                   cm_knn3_val$overall["AccuracyUpper"]),
                        PPV=c(cm_knn3$byClass['Pos Pred Value'],
                           cm_knn3_val$byClass['Pos Pred Value']), 
                     NPV=c(cm_knn3$byClass['Neg Pred Value'],
                           cm_knn3_val$byClass['Neg Pred Value']))


print(comp_knn3)
```

[@caret][@contour2024]

The decision graph confirms that as age and balance increase the algorithm was assigning that as 1 (churn).

The accuracy of the Test and Validation sets do not show any signs of over-training or over-smoothing.

This algorithm has the ability to predict on new data.

### Classification Trees

A Classification Tree model was created using a complexity parameter of 0.004166667, this is the minimum improvement required for the tree to create a new node. The variable used in tree construction are: active, age, balance, country, products and score. The model made 1223 correct predictions out of 6001 observations for a root node error of 0.2038.

```{r ct opt, include=FALSE}
# Classification Trees
if(!require(rpart)) install.packages("rpart", repos = "http://cran.us.r-project.org")
library(rpart)

# Optimize parameters
set.seed(4)
churn_ct <- train(churn ~ .,method = "rpart",
              tuneGrid = data.frame(cp = seq(0.0, 0.1, len = 25)),
              data = churn_cdp)
```

```{r Optimize Tree, echo=FALSE}
ggplot(churn_ct, hightlight = TRUE)
```

```{r ctree, include=FALSE}
# Train
set.seed(3)
churn_rpart <- rpart(churn ~ ., cp = 0.004166667, data = train_churn)
printcp(churn_rpart)

# map tree book 479
library(maptree)
draw.tree(churn_rpart, cex = 0.5, nodeinfo = TRUE)

# root node error = 0.20369
set.seed(4)
pred_rpart <- predict(churn_rpart, test_churn, type = "class")
cm_rpart <- confusionMatrix(pred_rpart, test_churn$churn)
cm_rpart

# compute accuracy = 0.8647

# Validate on the full data set 0.8637
set.seed(4)
val_rpart <- predict(churn_rpart, val_churn, type = "class")
cm_rpart_val <- confusionMatrix(val_rpart, val_churn$churn)
cm_rpart_val

scores <- scores %>%
  add_row(model = 'ctree', score = cm_rpart_val$overall["Accuracy"],
          PPV = cm_rpart_val$byClass['Pos Pred Value'], 
          NPV = cm_rpart_val$byClass['Neg Pred Value'])


```

```{r Tree Map, echo=FALSE}
if(!require(maptree)) install.packages("maptree", repos = "http://cran.us.r-project.org")
library(maptree)

draw.tree(churn_rpart, cex = 0.5, nodeinfo = TRUE)
```

```{r rpart validate and test comp, echo=FALSE}
comp_rpart <- data.frame(Model=c('Test', 'Validate'),
                        Accuracy=c(cm_rpart$overall["Accuracy"],
                                   cm_rpart_val$overall["Accuracy"]),
                        CI_Lower=c(cm_rpart$overall["AccuracyLower"],
                               cm_rpart_val$overall["AccuracyLower"]),
                        CI_Upper=c(cm_rpart$overall["AccuracyUpper"],
                                   cm_rpart_val$overall["AccuracyUpper"]),
                        PPV=c(cm_knn3$byClass['Pos Pred Value'],
                           cm_knn3_val$byClass['Pos Pred Value']), 
                     NPV=c(cm_knn3$byClass['Neg Pred Value'],
                           cm_knn3_val$byClass['Neg Pred Value']))


print(comp_rpart)
```

The Test and Validation results do not indicate any issues with the Classification Tree model and it ability to predict on new data.

[@caret] [@ggplot] [@rpart] [@maptree]

### SVM - Support Vector Machine

The radial method was used to create the SVM model with the parameters set to sigma = 0.06574296 and Cost = 1 from the results of optimization which created 2154 support vectors.

```{r svm opt, include=FALSE}
if(!require(e1071)) install.packages("e1071", repos = "http://cran.us.r-project.org")
if(!require(kernlab)) install.packages("kernlab", repos = "http://cran.us.r-project.org")
library(e1071)
library(kernlab)

# Optimize svm parameters radial method
set.seed(4)
churn_svmtr <- train(churn ~ ., method = "svmRadial", data = churn_cdp,
                     trControl = control)
```

```{r Optimize SVM, echo=TRUE}
ggplot(churn_svmtr, highlight = TRUE)
```

```{r svm, include=FALSE}
# Train
set.seed(3)
churn_svm <- svm(churn ~ ., sigma = 0.06574296, C = 1, data = train_churn)
summary(churn_svm)
plot(churn_svm$fitted)
# Test
set.seed(3)
pred_svm <- predict(churn_svm, test_churn, type = "class")
cm_svm <- confusionMatrix(pred_svm, test_churn$churn)
cm_svm

# compute accuracy = 0.8601

# Validate on the full data set 0.8612
set.seed(4)
val_svm <- predict(churn_svm, val_churn, type = "class")
cm_svm_val <- confusionMatrix(val_svm, val_churn$churn)
cm_svm_val

scores <- scores %>%
  add_row(model = 'svm', score = cm_svm_val$overall["Accuracy"],
          PPV = cm_svm_val$byClass['Pos Pred Value'], 
          NPV = cm_svm_val$byClass['Neg Pred Value'])

```

```{r svm test validate comp, echo=FALSE}
comp_svm <- data.frame(Model=c('Test', 'Validate'),
                        Accuracy=c(cm_svm$overall["Accuracy"],
                                   cm_svm_val$overall["Accuracy"]),
                        CI_Lower=c(cm_svm$overall["AccuracyLower"],
                               cm_svm_val$overall["AccuracyLower"]),
                        CI_Upper=c(cm_svm$overall["AccuracyUpper"],
                                   cm_svm_val$overall["AccuracyUpper"]),
                        PPV=c(cm_svm$byClass['Pos Pred Value'],
                           cm_svm_val$byClass['Pos Pred Value']), 
                     NPV=c(cm_svm$byClass['Neg Pred Value'],
                           cm_svm_val$byClass['Neg Pred Value']))


print(comp_svm)
```

The SVM model produces an overall accuracy level of 86.12% with the 95% confidence interval of (0.8543, 0.8679). The positive predictive value is 86.41% and the negative predictive value is 83.42%.

[@e1071][@kernlab][@adler2012]

### Random Forest

The Random Forest model was built using an minimum node of 140 and mtry set at 4, which is the number of variables to sample randomly as candidate at each split.

```{r rf opt , include=FALSE}
# load library for random forest
if(!require(randomForest)) install.packages("randomForest", repos = "http://cran.us.r-project.org")
if(!require(Rborist)) install.packages("Rborist", repos = "http://cran.us.r-project.org")
library(randomForest)

# use cross validation to optimize parameter

library(Rborist)
set.seed(3)
churn_rf <- train(churn ~ ., method = "Rborist",
      tuneGrid = data.frame(predFixed = 2, minNode = c(140, 200)),
                            data = churn_cdp)

# use turnRF to optimize mtry @randomForest
x <- churn %>% 
  select(-churn)

rf_tune <- tuneRF(x, churn_cdp$churn, mtryStart = 1 , ntreeTry=200, stepFactor=2, improve=0.05,
       trace=TRUE, plot=TRUE, doBest=FALSE)
```

```{r Optimize RF, echo=TRUE}
plot(churn_rf)
```

```{r mtry, echo=FALSE}
plot(rf_tune)
```

```{r random forest, include=FALSE}
# Create model with optimized parameters
set.seed(3)
churn_rft <- randomForest(churn ~ ., predFixed = 2, minNode = 140, 
                          mtry = 4, ntree = 200, data = train_churn)
summary(churn_rft)

# Test model 
set.seed(3)
pred_rf <- predict(churn_rft, test_churn, type = "class")
cm_rf <- confusionMatrix(pred_rf, test_churn$churn)
cm_rf

# Validate 
set.seed(4)
val_rf <- predict(churn_rft, val_churn, type = "class")
cm_rf_val <- confusionMatrix(val_rf, val_churn$churn)
cm_rf_val

scores <- scores %>%
  add_row(model = 'rf', score = cm_rf_val$overall["Accuracy"],
          PPV = cm_rf_val$byClass['Pos Pred Value'], 
          NPV = cm_rf_val$byClass['Neg Pred Value'])

```

```{r rf test validate comp}
# Compare Test and Validate
comp_rf <- data.frame(Model=c('Test', 'Validate'),
                        Accuracy=c(cm_rf$overall["Accuracy"],
                                   cm_rf_val$overall["Accuracy"]),
                        CI_Lower=c(cm_rf$overall["AccuracyLower"],
                               cm_rf_val$overall["AccuracyLower"]),
                        CI_Upper=c(cm_rf$overall["AccuracyUpper"],
                                   cm_rf_val$overall["AccuracyUpper"]),
                        PPV=c(cm_rf$byClass['Pos Pred Value'],
                           cm_rf_val$byClass['Pos Pred Value']), 
                     NPV=c(cm_rf$byClass['Neg Pred Value'],
                           cm_rf_val$byClass['Neg Pred Value']))


print(comp_rf)
```

The Random Forest model is nearly 100% accurate. Skeptical of these results mtry values of 2 and 3 were also tested which produced results from the low to high 90s. An mtry value less than 4 would produce a more conservative prediction.

[@randomForest][@Rborist]

## Results

Each model had their test model validated and the results compared. There was no indication in any of the models that there was any overfitting or biases.

```{r view scores, echo=FALSE}
print(scores)
```

The results indicate that the k Nearest Neighbor (kNN), Support Vector Machine (SVM), and Classification Tree (ctree) performed to withing 0.9% of one another ranging from 85.4% to 86.3%, in regards to overall accuracy.

Classification Tree has the second highest positive predictive value (PPV) of all the models at 86.4%, but the lowest negative predictive value (NPV) at 76.3%.

SVM and kNN have similar PPV and NPV scores.

Random Forest outperformed all models in every aspect and produced results near or at 100%

```{r Scores, include=FALSE}
s1 <-  scores %>% 
  ggplot(aes(reorder(model,score), score)) +
  geom_bar(stat = 'identity', col = 'black', fill = 'red') +
  labs(x = 'Model' , y = 'Score', title = 'Model Accuracy')

s2 <-  scores %>% 
  filter(PPV > 0) %>% 
  ggplot(aes(reorder(model, PPV), PPV)) +
  geom_bar(stat = 'identity', col = 'black', fill = 'red') +
  labs(x = 'Model' , y = 'PPV', title = 'Model PPV')

s3 <-  scores %>% 
  filter(NPV > 0) %>% 
  ggplot(aes(reorder(model, NPV), NPV)) +
  geom_bar(stat = 'identity', col = 'black', fill = 'red') +
  labs(x = 'Model' , y = 'NPV', title = 'Model NPV')

```

```{r Scores grid, echo=FALSE}
grid.arrange(s1, s2, s3, ncol = 3)
```

[@dplyr][@ggplot2][@gridExtra]

## Conclusion

The purpose of this exercise was to created a machine learning algorithm to predict bank churn using the Bank Churn Dataset. This is best achieved using the Random Forest model developed in this study. Random Forest has an overall accuracy of 90.07%, but more importantly its NPV - ability to predict churn is 95.4%.

The ability to predict churn gives the ABC Multinational Bank a tool to uncover customers who are in danger of leaving the Bank.

While this model can predict churn it does not have the ability to prevent churn. This study does provide insights on the affects of age, bank balance and credit score have on churn. Further investigation on these items may lead the Bank to develop different services to prevent churn. A break down of the types of products customers hold would also add value to any future study.
